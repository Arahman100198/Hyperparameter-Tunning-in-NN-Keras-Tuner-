{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TX1J-pmvnblB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/diabetes.csv')"
      ],
      "metadata": {
        "id": "vXHLNCgenlmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "vx5i8oO2nu_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,:-1] ## independent features\n",
        "y=df.iloc[:,-1] ## dependent features"
      ],
      "metadata": {
        "id": "EH-kZCVunweZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = StandardScaler()\n",
        "X = scalar.fit_transform(X)"
      ],
      "metadata": {
        "id": "XRF7Fr45n2T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "fPAXBO6noL6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import  Dense,Dropout\n",
        "from keras import Sequential\n"
      ],
      "metadata": {
        "id": "sXpQnc7xou26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32,activation = 'relu', input_dim = 8))\n",
        "model.add(Dense(1,activation='sigmoid',))\n",
        "\n",
        "model.compile(optimizer = 'adam',loss = 'binary_crossentropy',  metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "gx3Ru_egpJZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "ZQqw5V64qNmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train, batch_size= 32,epochs= 100,validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "id": "wlf5FPN4p08H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how to select the appropiate optimizer\n",
        "# no. of nodes/ neuron in a layer\n",
        "#how to select the number of layers\n",
        "# all in one model"
      ],
      "metadata": {
        "id": "0PnzWVPpqHIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner --upgrade\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nM16GIV5rSmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from keras_tuner import RandomSearch"
      ],
      "metadata": {
        "id": "CLLAnB-5rV0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "how to get the best optimizer"
      ],
      "metadata": {
        "id": "cHn1ypKyKnOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32,activation = 'relu', input_dim = 8))\n",
        "  model.add(Dense(1,activation='sigmoid',))\n",
        "  optimizers = hp.Choice('optimizers', values =['adam','sgd', 'rmsprop', 'adadelta'] )\n",
        "  model.compile(optimizer = optimizers,loss = 'binary_crossentropy',  metrics = ['accuracy'])\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "doHGZnUsrhu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,  # Run each trial once\n",
        "    directory='my_tuning_dir',\n",
        "    project_name='optimizer_tuning'\n",
        ")"
      ],
      "metadata": {
        "id": "A-G7xyUzsm13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, epochs=5,validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "9kwbon1ms7T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Results for all trials:\")\n",
        "for trial in tuner.oracle.get_best_trials(num_trials=len(tuner.oracle.trials)):\n",
        "    print(f\"Trial ID: {trial.trial_id}\")\n",
        "    print(f\"Optimizer: {trial.hyperparameters.get('optimizers')}\")\n",
        "\n",
        "    # Access the best validation accuracy value\n",
        "    val_accuracy = trial.metrics.get_best_value('val_accuracy')\n",
        "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "    print(\"---------------------------------------------------\")\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Best Optimizer: {best_hps.get('optimizers')}\")\n"
      ],
      "metadata": {
        "id": "nmefRKftuKNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "id": "FPXWWySPvY-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "BsL4IVgJwIMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "3_5bUnQDwc73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train, batch_size= 32,epochs= 100,initial_epoch=6,validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RDfwT0zHwnBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32,activation = 'relu', input_dim = 8))\n",
        "model.add(Dense(1,activation='sigmoid',))\n",
        "\n",
        "model.compile(optimizer = 'rmsprop',loss = 'binary_crossentropy',  metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "9Y2pQt6fw7k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train, batch_size= 32,epochs= 100,initial_epoch=6,validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "w2VGD0cixsoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "how to find best optimum number of nodes per layer"
      ],
      "metadata": {
        "id": "8A4MYtw7KZ-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner import RandomSearch\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define a function to build the model, with units as a tunable hyperparameter\n",
        "def build_model(hp):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Define a tunable number of units for the hidden layer (between 32 and 256)\n",
        "    model.add(layers.Dense(units=hp.Int('units', min_value=8, max_value=128),\n",
        "                           activation='relu', input_shape=(X_train.shape[1],)))\n",
        "\n",
        "    # Output layer for binary classification\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model with RMSprop optimizer (fixed)\n",
        "    model.compile(optimizer=optimizers.RMSprop(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Set up the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',  # Optimize validation accuracy\n",
        "    max_trials=5,               # Number of trials to run\n",
        "    executions_per_trial=1,     # Number of executions per trial\n",
        "    directory='my_tuning_dir',  # Directory for storing tuning results\n",
        "    project_name='best_units_tuning',  # Name of the project\n",
        "    overwrite=True             # Overwrite previous results\n",
        ")\n",
        "\n",
        "# Debugging: Print the shapes of the training and validation data\n",
        "print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation data shape: {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# Run the tuner search to find the best number of units\n",
        "tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Get the best hyperparameters after the search\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print all the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", best_hps.values)\n",
        "\n",
        "# Extract the best 'units' from the best hyperparameters\n",
        "# Extract the best 'units' from the best hyperparameters using the correct method\n",
        "best_units = best_hps['units']\n",
        "\n",
        "# If 'units' is found, print it\n",
        "print(f\"Best Number of Units for Hidden Layer: {best_units}\")\n",
        "\n",
        "\n",
        "# If 'units' is found, print it\n",
        "if best_units:\n",
        "    print(f\"Best Number of Units for Hidden Layer: {best_units}\")\n",
        "else:\n",
        "    print(\"No 'units' found in best hyperparameters.\")\n",
        "\n",
        "# Build the best model with the best hyperparameters\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the best model further\n",
        "history = best_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Print a summary of the training process\n",
        "print(\"\\nTraining Summary:\")\n",
        "print(\"History:\", history.history)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q9cuni3X4h43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.fit(X_train, y_train, batch_size= 32,epochs=100,initial_epoch= 6, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fDCPr37F5syt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the metrics from the history object\n",
        "train_loss = history.history['loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Calculate the average for each metric\n",
        "avg_train_loss = sum(train_loss) / len(train_loss)\n",
        "avg_train_accuracy = sum(train_accuracy) / len(train_accuracy)\n",
        "avg_val_loss = sum(val_loss) / len(val_loss)\n",
        "avg_val_accuracy = sum(val_accuracy) / len(val_accuracy)\n",
        "\n",
        "# Print the average values\n",
        "print(f\"Average Training Loss: {avg_train_loss}\")\n",
        "print(f\"Average Training Accuracy: {avg_train_accuracy}\")\n",
        "print(f\"Average Validation Loss: {avg_val_loss}\")\n",
        "print(f\"Average Validation Accuracy: {avg_val_accuracy}\")"
      ],
      "metadata": {
        "id": "2hc-YHc27FvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the metrics from the history object\n",
        "train_loss = history.history['loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Calculate the average for each metric\n",
        "avg_train_loss = sum(train_loss) / len(train_loss)\n",
        "avg_train_accuracy = sum(train_accuracy) / len(train_accuracy)\n",
        "avg_val_loss = sum(val_loss) / len(val_loss)\n",
        "avg_val_accuracy = sum(val_accuracy) / len(val_accuracy)\n",
        "\n",
        "# Calculate the best (minimum for loss and validation loss, maximum for accuracy and validation accuracy)\n",
        "best_train_loss = min(train_loss)\n",
        "best_train_accuracy = max(train_accuracy)\n",
        "best_val_loss = min(val_loss)\n",
        "best_val_accuracy = max(val_accuracy)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Average Training Loss: {avg_train_loss}\")\n",
        "print(f\"Average Training Accuracy: {avg_train_accuracy}\")\n",
        "print(f\"Average Validation Loss: {avg_val_loss}\")\n",
        "print(f\"Average Validation Accuracy: {avg_val_accuracy}\")\n",
        "\n",
        "print(f\"\\nBest Training Loss: {best_train_loss}\")\n",
        "print(f\"Best Training Accuracy: {best_train_accuracy}\")\n",
        "print(f\"Best Validation Loss: {best_val_loss}\")\n",
        "print(f\"Best Validation Accuracy: {best_val_accuracy}\")\n"
      ],
      "metadata": {
        "id": "gS9Z8s0c8MQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the best model using the hyperparameters found by the tuner\n",
        "best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Train the model with the best units\n",
        "history = best_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Extract the metrics from the history object\n",
        "train_loss = history.history['loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Calculate the average for each metric\n",
        "avg_train_loss = sum(train_loss) / len(train_loss)\n",
        "avg_train_accuracy = sum(train_accuracy) / len(train_accuracy)\n",
        "avg_val_loss = sum(val_loss) / len(val_loss)\n",
        "avg_val_accuracy = sum(val_accuracy) / len(val_accuracy)\n",
        "\n",
        "# Calculate the best (minimum for loss and validation loss, maximum for accuracy and validation accuracy)\n",
        "best_train_loss = min(train_loss)\n",
        "best_train_accuracy = max(train_accuracy)\n",
        "best_val_loss = min(val_loss)\n",
        "best_val_accuracy = max(val_accuracy)\n",
        "\n",
        "# Print the results\n",
        "print(f\"\\nAverage Training Loss: {avg_train_loss}\")\n",
        "print(f\"Average Training Accuracy: {avg_train_accuracy}\")\n",
        "print(f\"Average Validation Loss: {avg_val_loss}\")\n",
        "print(f\"Average Validation Accuracy: {avg_val_accuracy}\")\n",
        "\n",
        "print(f\"\\nBest Training Loss: {best_train_loss}\")\n",
        "print(f\"Best Training Accuracy: {best_train_accuracy}\")\n",
        "print(f\"Best Validation Loss: {best_val_loss}\")\n",
        "print(f\"Best Validation Accuracy: {best_val_accuracy}\")\n"
      ],
      "metadata": {
        "id": "CNr4J44h8X9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we will see how to select the number of layers using keras tuner (hyperparameter tunning)..."
      ],
      "metadata": {
        "id": "We3klAEpB4_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to find num of layers\n",
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(63,activation = 'relu', input_dim = 8))\n",
        "  for i in range(hp.Int('num_layer',min_value = 1, max_value=10,)):\n",
        "    model.add(Dense(63, activation= 'relu'))\n",
        "  model.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "  model.compile(optimizer = 'rmsprop',loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "df3yaNkO83fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(build_model,\n",
        "                     objective= 'val_accuracy',\n",
        "                     max_trials = 5,\n",
        "                     directory = 'my_tuning_dir',\n",
        "                     project_name = 'num_layers',\n",
        "                     overwrite=True)"
      ],
      "metadata": {
        "id": "wYa9Ylv5DWcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JAqa8PLiE-fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train,y_train, epochs = 5, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "WdrLHyxNEDSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "id": "3-4UH9kpFB9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "Iwc3wahHFQSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train, epochs=100, initial_epoch = 6, validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "G-xVkj9AFYna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "\n",
        "  counter = 0\n",
        "\n",
        "  for i in range(hp.Int('num_layer',min_value = 1, max_value=10)):\n",
        "\n",
        "    if counter == 0:\n",
        "      model.add(\n",
        "          Dense(\n",
        "              units=hp.Int('units' + str(i), min_value=8, max_value=128, step =8),\n",
        "              activation =hp.Choice('activation' + str(i), values = ['relu','sigmoid','tanh']),\n",
        "              input_dim=8\n",
        "              )\n",
        "      )\n",
        "    else:\n",
        "      model.add(\n",
        "          Dense(\n",
        "              units=hp.Int('units' + str(i), min_value=8, max_value=128, step =8),\n",
        "              activation =hp.Choice('activation' + str(i), values = ['relu','sigmoid','tanh']),\n",
        "\n",
        "              )\n",
        "      )\n",
        "    counter += 1\n",
        "  model.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "  optimizers = hp.Choice('optimizers', values =['adam','sgd', 'rmsprop', 'adadelta'] )\n",
        "  model.compile(optimizer = optimizers,loss = 'binary_crossentropy',  metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fWJQthRUFumV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(build_model,\n",
        "                     objective= 'val_accuracy',\n",
        "                     max_trials = 5,\n",
        "                     directory = 'my_tuning_dir',\n",
        "                     project_name = 'all of all',\n",
        "                     overwrite=True)"
      ],
      "metadata": {
        "id": "VO2jmiRjGIC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train,y_train, epochs = 5, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "nUiRTZTUJI1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "id": "b__1UZ3GJuBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =  tuner.get_best_models(num_models =1)[0]"
      ],
      "metadata": {
        "id": "-vh2KE4YL5J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs =200, initial_epoch = 6, validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "W_oQjWYxMUiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the validation accuracy decreasing so we use the drop out layer in this ."
      ],
      "metadata": {
        "id": "Ky-E6GZFNlOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras_tuner import HyperParameters\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Initialize counter\n",
        "    counter = 0\n",
        "\n",
        "    # Loop to create layers based on hyperparameters\n",
        "    for i in range(hp.Int('num_layer', min_value=1, max_value=10)):\n",
        "        if counter == 0:  # First layer has input_dim\n",
        "            model.add(\n",
        "                Dense(\n",
        "                    units=hp.Int('units_' + str(i), min_value=8, max_value=128, step=8),\n",
        "                    activation=hp.Choice('activation_' + str(i), values=['relu', 'sigmoid', 'tanh']),\n",
        "                    input_dim=8\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            model.add(\n",
        "                Dense(\n",
        "                    units=hp.Int('units_' + str(i), min_value=8, max_value=128, step=8),\n",
        "                    activation=hp.Choice('activation_' + str(i), values=['relu', 'sigmoid', 'tanh'])\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Adding Dropout after each Dense layer\n",
        "        model.add(\n",
        "            Dropout(\n",
        "                hp.Choice(\"dropout_\" + str(i), values=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Increment the counter after adding the layer\n",
        "        counter += 1\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Hyperparameter for optimizer\n",
        "    optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop', 'adadelta'])\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "WQJn2D8UMlxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(build_model,\n",
        "                     objective= 'val_accuracy',\n",
        "                     max_trials = 5,\n",
        "                     directory = 'my_tuning_dir',\n",
        "                     project_name = 'all of all-final',\n",
        "                     overwrite=True)"
      ],
      "metadata": {
        "id": "a2Ew1YCgOzw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train,y_train, epochs = 5, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "YEfotfIiPYaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "metadata": {
        "id": "E5t3yoBtP3b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =  tuner.get_best_models(num_models =1)[0]"
      ],
      "metadata": {
        "id": "ow8WCrYPP6gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs =200, initial_epoch = 6, validation_data = (X_test,y_test))"
      ],
      "metadata": {
        "id": "J0epblz5P8Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract accuracy and validation accuracy from the history object\n",
        "history_dict = history.history\n",
        "train_acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.plot(train_acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fXYjmczOP_oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pEFmLJUzQm2M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}